{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "from transformers import ElectraTokenizerFast, ElectraModel, TFElectraModel\n",
    "from transformers import AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset2.csv', nrows=10000)\n",
    "X = df['문법교정']\n",
    "y = df['malicious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='')\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x\n",
    "\n",
    "X = X.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "# tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "\n",
    "# typos_corrector = pipeline(\n",
    "#     \"text2text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     device=0 if torch.cuda.is_available() else -1,\n",
    "#     framework=\"pt\",\n",
    "# )\n",
    "\n",
    "# X = X.apply(lambda x: typos_corrector(x,\n",
    "#             max_length=128,\n",
    "#             num_beams=5,\n",
    "#             early_stopping=True)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Validation Loss: 0.6920426301956176, Validation Accuracy: 0.5235\n",
      "Epoch 2/10, Validation Loss: 0.6921260976791381, Validation Accuracy: 0.5235\n",
      "Epoch 3/10, Validation Loss: 0.6920457892417907, Validation Accuracy: 0.5235\n",
      "Epoch 4/10, Validation Loss: 0.6920511875152587, Validation Accuracy: 0.5235\n",
      "Epoch 5/10, Validation Loss: 0.6925025310516357, Validation Accuracy: 0.5235\n",
      "Epoch 6/10, Validation Loss: 0.6926042494773865, Validation Accuracy: 0.5235\n",
      "Epoch 7/10, Validation Loss: 0.6922600531578064, Validation Accuracy: 0.5235\n",
      "Epoch 8/10, Validation Loss: 0.6920434393882752, Validation Accuracy: 0.5235\n",
      "Epoch 9/10, Validation Loss: 0.6920547103881836, Validation Accuracy: 0.5235\n",
      "Epoch 10/10, Validation Loss: 0.6924946007728576, Validation Accuracy: 0.5235\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "\n",
    "X_list = X.values.tolist()\n",
    "y = y.values\n",
    "sequences = tokenizer(X_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences['input_ids'], y, test_size=0.2, random_state=42)\n",
    "X_train_mask, X_test_mask, _, _ = train_test_split(sequences['attention_mask'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, X_train_mask, torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset = TensorDataset(X_test, X_test_mask, torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, dropout=self.dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout_layer(self.embedding(x))\n",
    "        out, _ = self.lstm(embedded)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "input_size = len(tokenizer)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "\n",
    "model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            val_losses.append(criterion(outputs, labels).item())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "            val_accs.append(acc)\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = np.mean(val_accs)\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
